
import json
from typing import Dict, Any, List, Optional
from openai import OpenAI, OpenAIError
from app.core.config import settings
from app.core import prompts

class LLMService:
    def __init__(self):
        self.api_key = settings.OPENAI_API_KEY
        self.model = settings.OPENAI_MODEL
        self.client = None
        
        if self.api_key:
            self.client = OpenAI(api_key=self.api_key)
        else:
            print("WARNING: OPENAI_API_KEY not found. Running in MOCK mode.")

    def _call_llm(self, system_prompt: str, user_prompt: str, response_format: str = "json_object") -> Dict[str, Any]:
        """
        Generic method to call OpenAI Chat Completion.
        """
        if not self.client:
            raise ValueError("OpenAI Client not initialized. Check API Key.")

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": response_format},
                temperature=0.7,
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except OpenAIError as e:
            print(f"OpenAI API Error: {e}")
            raise e
        except json.JSONDecodeError:
            print(f"Failed to decode JSON from LLM: {content}")
            raise ValueError("Invalid JSON response from LLM")
        except Exception as e:
            print(f"Generic Error in call_llm: {e}")
            raise e

    def generate_plan(self, user_profile: Dict, goals: List[Dict], content_catalog: List[Dict]) -> Dict[str, Any]:
        if not self.client:
            # Fallback Mock
            return self._mock_plan(user_profile)

        user_content = f"""
        User Profile: {json.dumps(user_profile)}
        Goals: {json.dumps(goals)}
        Content Catalog: {json.dumps(content_catalog)}
        """
        return self._call_llm(prompts.PLAN_GENERATION_SYSTEM_PROMPT, user_content)

    def replan(self, current_plan: Dict, recent_events: List[Dict], skill_state: List[Dict]) -> Dict[str, Any]:
        if not self.client:
            return {"plan": current_plan, "changeSummary": "Mock Replan: No changes."}

        user_content = f"""
        Current Plan: {json.dumps(current_plan)}
        Recent Events: {json.dumps(recent_events)}
        Skill State: {json.dumps(skill_state)}
        """
        return self._call_llm(prompts.REPLAN_SYSTEM_PROMPT, user_content)

    def generate_next_item(self, domain: str, mastery: float, recent_history: List[Dict]) -> Dict[str, Any]:
        if not self.client:
            return self._mock_item(domain)

        user_content = f"""
        Domain: {domain}
        Current Mastery: {mastery}
        Recent History: {json.dumps(recent_history)}
        """
        return self._call_llm(prompts.NEXT_ITEM_SYSTEM_PROMPT.format(domain=domain, mastery=mastery), user_content)

    def generate_feedback(self, item_stem: str, correct_answer: str, user_answer: str, is_correct: bool) -> Dict[str, Any]:
        if not self.client:
            return {"isCorrect": is_correct, "feedbackMessage": "Mock Feedback: Good job."}

        user_content = json.dumps({
            "stem": item_stem,
            "correct_answer": correct_answer,
            "user_answer": user_answer,
            "is_correct": is_correct
        })
        formatted_system = prompts.FEEDBACK_SYSTEM_PROMPT.format(
            stem=item_stem, 
            correct_answer=correct_answer, 
            user_answer=user_answer, 
            is_correct=is_correct
        )
        return self._call_llm(formatted_system, user_content)

        return self._call_llm(formatted_system, user_content)

    def generate_lessons(self, domain: str, n_lessons: int, locale: str = "es-ES") -> Dict[str, Any]:
        if not self.client:
            return {
                "lessons": [
                    {
                        "title": f"Mock Lesson for {domain}",
                        "description": "Generated by Mock",
                        "body": "# Mock Content\nThis is a mock lesson.",
                        "estimatedMinutes": 10,
                        "difficulty": 0.5,
                        "type": "lesson"
                    }
                ]
            }
        
        system_prompt = prompts.CONTENT_GENERATION_SYSTEM_PROMPT.format(domain=domain, n_lessons=n_lessons, locale=locale)
        user_prompt = f"Generate {n_lessons} lessons for topic: {domain}"
        return self._call_llm(system_prompt, user_prompt)

    # --- Mocks for Fallback ---
    def _mock_plan(self, profile):
        return {
            "plan": {
                 "planId": "mock-plan-id",
                 "userId": profile.get("userId", "unknown"),
                 "status": "draft",
                 "modules": []
            },
            "rawModelOutput": {"note": "Generated by Mock logic"}
        }

    def _mock_item(self, domain):
         return {
            "item": {
                "tempId": "mock-item-id",
                "type": "multiple_choice",
                "stem": f"Mock question for {domain}",
                "options": [],
                "difficulty": 0.5
            },
            "rationale": "Mock rationale"
        }

llm_service = LLMService()
